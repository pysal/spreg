<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Estimating SLX Models &#8212; spreg v1.8.6.dev8+g715b6dea5 Manual</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css?v=9afac83c" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/pysal-styles.css?v=b100b7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <script src="../_static/documentation_options.js?v=c2ae4888"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}}, "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/pysal_favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Maximum Likelihood Estimation - Spatial Lag Model" href="13_ML_estimation_spatial_lag.html" />
    <link rel="prev" title="Distance Decay" href="11_distance_decay.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          spreg</a>
        <span class="navbar-text navbar-version pull-left"><b>1.8.6.dev8+g715b6dea5</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../installation.html">Installation</a></li>
                <li><a href="../tutorials.html">Tutorials</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="../references.html">References</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1_sample_data.html">PySAL Sample Data Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_data_input_output.html">Data Input/Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_basic_mapping.html">Basic Mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_spatial_weights.html">Spatial Weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_OLS.html">Basic Ordinary Least Squares Regression (OLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_TWOSLS.html">Two Stage Least Squares Regression (2SLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7_spatial_models.html">Spatial Model Specifications</a></li>
<li class="toctree-l2"><a class="reference internal" href="8_spatial_multipliers.html">Spatial Multipliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="9_specification_tests.html">Specification Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_specification_tests_properties.html">Specification Tests - Properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_distance_decay.html">Distance Decay</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Estimating SLX Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_ML_estimation_spatial_lag.html">Maximum Likelihood Estimation - Spatial Lag Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="14_IV_estimation_spatial_lag.html">Instrumental Variables Estimation - Spatial Lag Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="15_ML_estimation_spatial_error.html">Maximum Likelihood Estimation - Spatial Error Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_GMM_estimation_spatial_error.html">GMM Estimation - Spatial Error Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_GMM_higher_order.html">GMM Estimation - Higher Order Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Panel_FE_example.html">Spatial Panel Models with Fixed Effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="skater_reg.html">Skater Regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api.html#classic-models">Classic Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#spatial-regression-models">Spatial Regression Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#discrete-choice-models">Discrete Choice Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#regimes-models">Regimes Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#seemingly-unrelated-regressions">Seemingly-Unrelated Regressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#spatial-panel-models">Spatial Panel Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#diagnostics">Diagnostics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#spatial-specification-search">Spatial Specification Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#dgp">DGP</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Estimating SLX Models</a><ul>
<li><a class="reference internal" href="#Luc-Anselin">Luc Anselin</a></li>
<li><a class="reference internal" href="#(revised-09/17/2024)">(revised 09/17/2024)</a><ul>
<li><a class="reference internal" href="#Preliminaries">Preliminaries</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#Modules-Needed">Modules Needed</a></li>
<li><a class="reference internal" href="#Functionality-Used">Functionality Used</a></li>
<li><a class="reference internal" href="#Data,-Weights-and-Variables">Data, Weights and Variables</a><ul>
<li><a class="reference internal" href="#id2">Estimating SLX Models</a></li>
<li><a class="reference internal" href="#Linear-SLX">Linear SLX</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Spatial-Weights">Spatial Weights</a></li>
<li><a class="reference internal" href="#Kernel-Weights">Kernel Weights</a><ul>
<li><a class="reference internal" href="#Estimating-Nonlinear-SLX-Models">Estimating Nonlinear SLX Models</a></li>
<li><a class="reference internal" href="#Negative-Exponential-Distance">Negative Exponential Distance</a><ul>
<li><a class="reference internal" href="#Adaptive-bandwidth">Adaptive bandwidth</a></li>
<li><a class="reference internal" href="#Fixed-bandwidth">Fixed bandwidth</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Inverse-Distance-Power">Inverse Distance Power</a><ul>
<li><a class="reference internal" href="#id3">Adaptive bandwidth</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Practice">Practice</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="admonition note">
<p>This page was generated from <a class="reference external" href="https://github.com/pysal/spreg/blob/master/notebooks/12_estimating_slx.ipynb">notebooks/12_estimating_slx.ipynb</a>.
Interactive online version:
<span class="raw-html"><a href="https://mybinder.org/v2/gh/pysal/spreg/master?filepath=notebooks/12_estimating_slx.ipynb"><img alt="Binder badge" src="https://mybinder.org/badge_logo.svg" style="vertical-align:text-bottom"></a></span></p>
</div>
<section id="Estimating-SLX-Models">
<h1>Estimating SLX Models<a class="headerlink" href="#Estimating-SLX-Models" title="Link to this heading">¶</a></h1>
<section id="Luc-Anselin">
<h2>Luc Anselin<a class="headerlink" href="#Luc-Anselin" title="Link to this heading">¶</a></h2>
</section>
<section id="(revised-09/17/2024)">
<h2>(revised 09/17/2024)<a class="headerlink" href="#(revised-09/17/2024)" title="Link to this heading">¶</a></h2>
<section id="Preliminaries">
<h3>Preliminaries<a class="headerlink" href="#Preliminaries" title="Link to this heading">¶</a></h3>
<p>In this notebook, a closer look is taken at the estimation of SLX models, both the traditional linear specification as well as more recently introduced nonlinear forms.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">spreg</span></code> package implements the inclusion of spatially lagged explanatory variables in any specification by means of a non-zero <code class="docutils literal notranslate"><span class="pre">slx_lags</span></code> argument. This allows for the estimation of non-spatial linear models by means of OLS, as well as spatial Durbin and SLX-Error models by means of specialized methods. In addition, as of Version 1.7, the <code class="docutils literal notranslate"><span class="pre">NSLX</span></code> module introduces the estimation of nonlinear SLX models, such as a negative exponential distance function and an inverse distance power
transformation. The <code class="docutils literal notranslate"><span class="pre">NSLX</span></code> module is still somewhat experimental and under active development, but the current version is stable.</p>
</section>
</section>
<section id="Prerequisites">
<h2>Prerequisites<a class="headerlink" href="#Prerequisites" title="Link to this heading">¶</a></h2>
<p>Familiarity with the basic setup of regressions in <em>spreg</em> as well as essentials of <em>numpy</em>, <em>pandas</em>, <em>geopandas</em>, and <em>libpysal</em> is assumed. In addition, it is assumed that the <strong>chicagoSDOH</strong> PySAL sample data set has been installed (for specific instructions, refer to the <em>sample data notebook</em>).</p>
</section>
<section id="Modules-Needed">
<h2>Modules Needed<a class="headerlink" href="#Modules-Needed" title="Link to this heading">¶</a></h2>
<p>The main modules needed are <code class="docutils literal notranslate"><span class="pre">spreg.OLS</span></code> and <code class="docutils literal notranslate"><span class="pre">spreg.NLSX</span></code>. In addition, <em>libpysal</em> is needed for data import and spatial weights construction, and <em>geopandas</em> for data input from a shape file. This notebook is based on version 1.7 of <em>spreg</em>.</p>
<p>As before, only the needed functions from <em>libpysal</em> are imported, specifically, <code class="docutils literal notranslate"><span class="pre">get_path</span></code> from <code class="docutils literal notranslate"><span class="pre">libpysal.examples</span></code>, and <code class="docutils literal notranslate"><span class="pre">libpysal.weights</span></code> as <code class="docutils literal notranslate"><span class="pre">weights</span></code>.</p>
<p>Some additional imports are included to avoid excessive warning messages. With later versions of PySAL, these may not be needed. As before, the <code class="docutils literal notranslate"><span class="pre">set_printoptions</span></code> is used for <em>numpy</em> 2.0 and later.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import warnings
warnings.filterwarnings(&quot;ignore&quot;)
import os
os.environ[&#39;USE_PYGEOS&#39;] = &#39;0&#39;

import numpy as np
import pandas as pd
import geopandas as gpd
from libpysal.examples import get_path
import libpysal.weights as weights
from spreg import OLS, NSLX
np.set_printoptions(legacy=&quot;1.25&quot;)
</pre></div>
</div>
</div>
</section>
<section id="Functionality-Used">
<h2>Functionality Used<a class="headerlink" href="#Functionality-Used" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>from geopandas:</p>
<ul>
<li><p>read_file</p></li>
</ul>
</li>
<li><p>from libpysal:</p>
<ul>
<li><p>examples.get_path</p></li>
<li><p>weights.Queen.from_dataframe</p></li>
<li><p>weights.Kernel</p></li>
</ul>
</li>
<li><p>from spreg:</p>
<ul>
<li><p>OLS</p></li>
<li><p>NSLX</p></li>
</ul>
</li>
</ul>
</section>
<section id="Data,-Weights-and-Variables">
<h2>Data, Weights and Variables<a class="headerlink" href="#Data,-Weights-and-Variables" title="Link to this heading">¶</a></h2>
<p>As in the previous notebooks, all data sets, weights files and variables are specified at the top, so that they can be easily changed to other examples.</p>
<p>The data set is from the <strong>chicagoSDOH</strong> sample data set:</p>
<ul class="simple">
<li><p><strong>Chi-SDOH.shp,shx,dbf,prj</strong>: socio-economic indicators of health for 2014 in 791 Chicago tracts</p></li>
</ul>
<p>Contiguity weights and kernel weights are constructed by means of the <code class="docutils literal notranslate"><span class="pre">libpysal.weights</span></code> functionality. In addition to queen contiguity, adaptive bandwidth triangular kernel weights and adaptive bandwidth quadratic kernel weights are constructed with k=10. The contiguity weight is used in row-standardized form, the kernel weights are kept as is.</p>
<p>The model specification is purely to illustrate the various estimation methods and relates the variable <strong>HIS_ct</strong> (economic hardship index) to <strong>Blk14P</strong> (percentage Black households), <strong>Hisp14P</strong> (percentage Hispanic households), and <strong>EP_NOHSDP</strong> (percentage households without high school education).</p>
<p>The centroid coordinates <strong>COORD_X</strong> and <strong>COORD_Y</strong> are used to construct kernel weights.</p>
<p>The various initializations are carried out in two steps:</p>
<ul class="simple">
<li><p>first, all file names and variable names are defined</p></li>
<li><p>second, the files are read, the variables extracted, and the spatial weights constructed</p></li>
</ul>
<p>The first step allows for customization to other examples, the second step is agnostic to the actual files and variables that were specified. To keep the code simple, there are no error checks for missing files or mismatches in the variable names.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>infileshp = get_path(&quot;Chi-SDOH.shp&quot;)            # input shape file with data
y_name = &#39;HIS_ct&#39;
x_names = [&#39;Blk14P&#39;,&#39;Hisp14P&#39;,&#39;EP_NOHSDP&#39;]
ds_name = &#39;Chi-SDOH&#39;
wq_name = &#39;Chi-SDOH_q&#39;
wk10_name = &#39;Chi-SDOH_tri10&#39;
wkq10_name = &#39;Chi-SDOH_quad10&#39;
coordname = [&quot;COORD_X&quot;,&quot;COORD_Y&quot;]
idvar = &quot;ID&quot;
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dfs = gpd.read_file(infileshp)
wq = weights. Queen.from_dataframe(dfs,ids=idvar)
wq.transform = &#39;r&#39;    # row-transform the weights
y = dfs[y_name]
x = dfs[x_names]
crdnts = dfs[coordname]
wk10 = weights.Kernel(np.array(crdnts),k=10,fixed=False,diagonal=True)
wkq10 = weights.Kernel(np.array(crdnts),k=10,function=&quot;quadratic&quot;,fixed=False,diagonal=True)
</pre></div>
</div>
</div>
<section id="id2">
<h3>Estimating SLX Models<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>As of Version 1.7 of <em>spreg</em>, several options to estimate the SLX model are available that go beyond the simple inclusion of spatially lagged explanatory variables by means of a non-zero <code class="docutils literal notranslate"><span class="pre">slx_vars</span></code> argument. A distinction is made between a linear model and a nonlinear model. In the linear model, both the usual row-standardized spatial weights are supported, as well as kernel weights (not row-standardized). The kernel weights can be conceived as introducing a form of nonlinearity, albeit in the
weights and not in the coefficients. In contrast to other usage of the kernel weights (e.g., for HAC standard errors), in the SLX estimation, the diagonal elements are set to zero (and not kept as 1.0).</p>
<p>The nonlinear estimation is implemented for a negative exponential distance function and an inverse distance power function. Instead of using the actual distance between observations, which is dependent on the scale of the metric chosen (e.g., meters vs. miles), the actual distance within a given bandwidth (either fixed or adaptive) is converted to a fraction of the bandwidth distance, ensuring that its range is between 0 and 1. More precisely, the distance is converted to a fraction of the
distance to the nearest neighbor within the bandwidth (for fixed bandwidth) that is farthest away. For an adaptive bandwidth, this is always the k-nearest neighbor, for a fixed bandwidth, it is typically to a nearest neighbor for less than k.</p>
<p>The exponential model transformation is based on <span class="math notranslate nohighlight">\(e^{-\alpha z_{ij}}\)</span>, where <span class="math notranslate nohighlight">\(z_{ij} = d_{ij}/bw\)</span>, for <span class="math notranslate nohighlight">\(d_{ij} \le bw\)</span>, and zero otherwise. Note that the estimate for <span class="math notranslate nohighlight">\(\alpha\)</span> should be positive and larger than one. The negative exponential transformation is built-in, so that the estimate for <span class="math notranslate nohighlight">\(\alpha\)</span> should be a positive value. The current implementation in <em>spreg</em> has a different <span class="math notranslate nohighlight">\(\alpha\)</span> parameter for each explanatory variable.</p>
<p>For the power model, the transformation is <span class="math notranslate nohighlight">\(z_{ij}^\alpha\)</span> with <span class="math notranslate nohighlight">\(z_{ij} = 1 - d_{ij}/bw\)</span>, for <span class="math notranslate nohighlight">\(d_{ij} \le bw\)</span>, and zero otherwise. In this context, the estimate for <span class="math notranslate nohighlight">\(\alpha\)</span> should be positive and larger than one. Note that since <span class="math notranslate nohighlight">\(z_{ij} \lt 1\)</span>, the power <span class="math notranslate nohighlight">\(z_{ij}^\alpha\)</span> quickly becomes negligible (i.e., basically zero) for larger values of <span class="math notranslate nohighlight">\(\alpha\)</span>. Here too, a different parameter is estimated for each explanatory variable.</p>
<p>The estimation of the NSLX model uses a nonlinear optimization routine that is quite sensitive to the model specification. In ill-behaved specifications, nonsensical parameter estimates may result. In some instances, the model may fail to optimize altogether, yielding a <code class="docutils literal notranslate"><span class="pre">nan</span></code> for the objective function. Such cases should be taken as an indication of a poor specification and alternatives should be considered. In addition, one should keep in mind that the estimated coefficients should be small.
Large coefficients are applied to the transformed distance, which is a fraction less than one. For example, a coefficient of 10 in a power function applied to a z-distance of 0.2 results in a weight of 0.00000001, essentially zeroing out the lagged variable. Such large values can also easily result in singular covariance matrices.</p>
<p>The parameter estimates are also very sensitive to the choice of the bandwidth, a common attribute of kernel estimation methods. Since these are distance decay functions, larger values for the <span class="math notranslate nohighlight">\(\alpha\)</span> parameters imply a steeper decline with distance. Everything else being the same, the same actual distance decay will tend to yield larger parameter values for a larger bandwidth, and vice versa. Unlike what holds in the linear model, the actual parameter values are not easy to interpret in
an absolute sense. However, their effect on the multipliers can be assessed by means of the methods covered in an earlier notebook.</p>
<p>For all models, there is the flexibility to only lag some of the explanatory variables. In addition, for the nonlinear models, it is possible to apply a different transformation to each variable. Unless there is a good theoretical reason to do so, this is generally not recommended.</p>
</section>
<section id="Linear-SLX">
<h3>Linear SLX<a class="headerlink" href="#Linear-SLX" title="Link to this heading">¶</a></h3>
</section>
</section>
<section id="Spatial-Weights">
<h2>Spatial Weights<a class="headerlink" href="#Spatial-Weights" title="Link to this heading">¶</a></h2>
<p>As a point of reference, the first estimation is for a classic regression by means of OLS. Spatial diagnostics are included as well.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ols1 = OLS(y,x,w=wq,spat_diag=True,
                 name_w=wq_name,name_ds=ds_name)
print(ols1.summary)
</pre></div>
</div>
</div>
<p>The three regression coefficients are positive and highly significant. The overall fit is quite good, with an adjusted <span class="math notranslate nohighlight">\(R^2\)</span> of 0.82 and associated sum of squared residuals of 26,459.9. Nevertheless, all the spatial diagnostics and their robust forms are highly significant, pointing to the presence of spatial effects. Specifically, the LM test for WX and its robust form are both significant as well, although it would seem that a lag model and/or a spatial Durbin specification may be most
appropriate as the alternative.</p>
<p>Importantly, the values of the robust statistics are all smaller than the original statistic, suggesting the appropriateness of the alternatives considered. In other words, all spatial models considered could be viable alternatives.</p>
<p>The linear SLX model with queen contiguity weights is invoked by means of <code class="docutils literal notranslate"><span class="pre">OLS</span></code> with the usual arguments, and with <code class="docutils literal notranslate"><span class="pre">slx_lags=1</span></code>. Spatial diagnostics are included as well (<code class="docutils literal notranslate"><span class="pre">spat_diag=True</span></code>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxw1 = OLS(y,x,w=wq,slx_lags=1,
                 spat_diag=True,
                 name_w=wq_name,name_ds=ds_name)
print(slxw1.summary)
</pre></div>
</div>
</div>
<p>The overall fit of the model improves only slightly, to an adjusted <span class="math notranslate nohighlight">\(R^2\)</span> of 0.84, with a sum of squared residuals of 23,475.4. All lag terms are highly significant, but two of them are negative (<strong>W_Blk14P</strong> and <strong>W_Hisp14P</strong>), while the third one (<strong>W_EP_NOHSDP</strong>) is positive. The interpretation of negative coefficients for the spatial lags is difficult, so this may point to a misspecification. While significant, the coefficient of <strong>W_EP_NOHSDP</strong> is slightly larger than that of the
coefficient itself, which runs counter to Tobler’s law.</p>
<p>The inclusion of the SLX terms changes the spatial diagnostics. The original LM-Lag and LM-Error tests are still (very) significant, but their robust forms are not.</p>
<p>Higher order lags are obtained by setting <code class="docutils literal notranslate"><span class="pre">slx_lags</span></code> to a value larger than one. However, this very quickly leads to problems with multicollinearity. To illustrate this property, the option <code class="docutils literal notranslate"><span class="pre">vif</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>. With <code class="docutils literal notranslate"><span class="pre">slx_lags</span> <span class="pre">=</span> <span class="pre">2</span></code>, the other arguments are as before.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxw2 = OLS(y,x,w=wq,slx_lags=2,
                 spat_diag=True,vif=True,
                 name_w=wq_name,name_ds=ds_name)
print(slxw2.summary)
</pre></div>
</div>
</div>
<p>The inclusion of the second order lags results in all lag terms but the first order lag of <strong>EP_NOHSDP</strong> to become non-significant. In addition, the multicollinearity is very problematic. The condition number is 89, well above the usual acceptable range. The VIF statistics show the problem with the spatially lagged variables, with a VIF value of almost 157 for <strong>W2_Blk14P</strong>. The effect on the spatial diagnostics is the same as with the first order lags: both LM-Lag and LM-Error tests are
significant, but their robust versions are not.</p>
<p>Clearly, in this example, nothing is gained by including the higher order lags.</p>
<p>Since the coefficient of <strong>W_EP_NOHSDP</strong> was least problematic in the first order model, <code class="docutils literal notranslate"><span class="pre">slx_vars</span></code> is used to remove the other lag terms. To this effect, it is set to the list <code class="docutils literal notranslate"><span class="pre">[False,False,True]</span></code> (the default is otherwise <code class="docutils literal notranslate"><span class="pre">slx_vars=&quot;All&quot;</span></code>), which will eliminate <strong>W_Blk14P</strong> and <strong>W_Hisp14P</strong> from the regression specification. All the other arguments are as before.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxw3 = OLS(y,x,w=wq,slx_lags=1,slx_vars=[False,False,True],
                 spat_diag=True,
                 name_w=wq_name,name_ds=ds_name)
print(slxw3.summary)
</pre></div>
</div>
</div>
<p>The inclusion of the spatial lag for just <strong>EP_NOHSDP</strong> makes the coefficient of <strong>Hisp14P</strong> not significant. On the other hand, the coefficient of the lag term is now smaller than that of the non-lagged variable, conforming to Tobler’s law. The fit still gives an adjusted <span class="math notranslate nohighlight">\(R^2\)</span> of 0.84, with a residual sum of squares of 24,117.4.</p>
<p>The spatial diagnostics seem to point to potential spatial error dependence, with both the LM test and its robust form highly significant.</p>
</section>
<section id="Kernel-Weights">
<h2>Kernel Weights<a class="headerlink" href="#Kernel-Weights" title="Link to this heading">¶</a></h2>
<p>Kernel weights can be passed to an estimation routine in the same way as other weights, but only for <code class="docutils literal notranslate"><span class="pre">slx_lags</span> <span class="pre">=</span> <span class="pre">1</span></code>. If a higher order lag is specified, <code class="docutils literal notranslate"><span class="pre">spreg</span></code> will raise an <code class="docutils literal notranslate"><span class="pre">Exception</span></code>. Also, the interpretation of the results is different from the standard linear case. While the diagonal elements as set to zero, just as for other spatial weights, kernel weights are <em>not</em> row-standardized. As a result, the magnitude of the associated coefficients is not directly comparable to the
non-lagged counterparts. A detailed look at the implied multiplier effects can be gained by means of the <code class="docutils literal notranslate"><span class="pre">i_multiplier</span></code> function, as illustrated in a previous notebook.</p>
<p>Also, importantly, the results of the diagnostics for spatial effects are not valid for kernel weights without adjustments, so they cannot be activated.</p>
<p>In all other respects, the command is identical to the standard case.</p>
<p>The first example is for adaptive bandwidth triangular kernel weights with k=10, contained in <strong>wk10</strong>. Note that <code class="docutils literal notranslate"><span class="pre">spat_diag=True</span></code> is specified, even though this option is not available for kernel weights. As a result, the output will include a warning.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxk1 = OLS(y,x,w=wk10,slx_lags=1,spat_diag=True,
                 name_w=wk10_name,name_ds=ds_name)
print(slxk1.summary)
</pre></div>
</div>
</div>
<p>As in the linear case, all lag coefficient are significant, with negative signs for <strong>W_Blk14P</strong> and <strong>W_Hisp14P</strong>. In contrast to the linear case, the magnitude of the coefficients of the lag terms is not directly comparable to the original coefficient.</p>
<p>In terms of fit, the results are similar to that of the linear model, with an adjusted <span class="math notranslate nohighlight">\(R^2\)</span> around 0.84 and a sum of squared residuals of 23,811.7 (compared to 23,475.4 for queen contiguity).</p>
<p>The results for the reduced model follow.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxk2 = OLS(y,x,w=wk10,slx_lags=1,spat_diag=True,
                 slx_vars=[False,False,True],
                 name_w=wk10_name,name_ds=ds_name)
print(slxk2.summary)
</pre></div>
</div>
</div>
<p>The same effect as in the linear model is observed, with <strong>Hisp14P</strong> becoming non-significant. The model fit is barely affected, with a sum of squared residuals of 24,602.7.</p>
<p>An alternative kernel function is the adaptive bandwidth quadratic function with k=10, given by <strong>wkq10</strong>. This second specification is considered next, first for all three variables, then for just <strong>W_NOHSDP</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxk3 = OLS(y,x,w=wkq10,slx_lags=1,
                 slx_vars = &quot;All&quot;,
                 name_w=wkq10_name,name_ds=ds_name)
print(slxk3.summary)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>slxk4 = OLS(y,x,w=wkq10,slx_lags=1,
                 slx_vars = [False,False,True],
                 name_w=wkq10_name,name_ds=ds_name)
print(slxk4.summary)
</pre></div>
</div>
</div>
<p>The same pattern is observed as for the other weights. With the full model, all coefficients are highly significant, but <strong>W_Blk14P</strong> and <strong>W_Hisp14P</strong> have negative signs. When just <strong>W_EP_NOHSDP</strong> is included, <strong>Hisp14P</strong> becomes insignificant.</p>
<p>The fit of the three specifications considered so far is very similar. Comparing the sum of squared residuals (the criterion of fit also used for the nonlinear models) for the reduced model, the linear SLX model achieves 24,117.4, the triangular kernel 24,602.7, and the quadratic kernel 24,535.3. In this example, there is very little difference between the three models.</p>
<section id="Estimating-Nonlinear-SLX-Models">
<h3>Estimating Nonlinear SLX Models<a class="headerlink" href="#Estimating-Nonlinear-SLX-Models" title="Link to this heading">¶</a></h3>
<p>As mentioned, estimating nonlinear models can be quite tricky. The optimization routines are sensitive to model (mis)specifications and various numerical approximations can yield nonsensical results. So far, the <code class="docutils literal notranslate"><span class="pre">NSLX</span></code> module implements two specifications, a negative exponential distance function and an inverse distance power function.</p>
<p><code class="docutils literal notranslate"><span class="pre">NSLX</span></code> uses the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> routine from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> as the nonlinear optimizer. The default method is <code class="docutils literal notranslate"><span class="pre">BFGS</span></code> (Broyden, Fletcher, Goldfard and Shanno), a quasi-Newton method that uses a numerical approximation for the first derivatives. Starting values for the parameters are the OLS regression estimates for the <span class="math notranslate nohighlight">\(\beta\)</span> coefficients and 1.0 for the <span class="math notranslate nohighlight">\(\alpha\)</span> coefficients (this is currently hard-coded). The optimization method also returns an approximation of the inverse
Hessian, which can be used to compute asymptotic standard errors. However, as documented online in various forums, depending on the model, the approximation can be quite crude.</p>
<p>Since the nonlinear SLX model consists of both a linear and a nonlinear part that are unrelated, the associated variance-covariance matrix is block-diagonal. The block for the linear part is the familiar <span class="math notranslate nohighlight">\(\sigma^2 (X'X)^{-1}\)</span>, which is easy to compute. The block for the nonlinear part is <span class="math notranslate nohighlight">\(\sigma^2 (\hat{X}'\hat{X})^{-1}\)</span>, where <span class="math notranslate nohighlight">\(\hat{X}\)</span> consists of vectors of partial derivatives with respect to the nonlinear parameters, with their final values substituted. Both blocks are
relatively straightforward to compute analytically. Specifically, the expressions for the partial derivatives with respect to <span class="math notranslate nohighlight">\(\alpha\)</span> are <span class="math notranslate nohighlight">\(- e^{-\alpha.z}.ln(\alpha.z).z\)</span> for the exponential model, and <span class="math notranslate nohighlight">\(z^\alpha.ln(z)\)</span> for the power model.</p>
<p>The nonlinear part is notoriously ill-behaved, especially for the power model when the parameter estimates are much larger than one. In such instances, the model should be viewed with suspicion, given the problems with such powers, even though the numerical approximation may yield what looks like a valid variance-covariance function.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">NSLX</span></code> class takes a set of arguments that is slightly different from that for the other regression functions. As usual, <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">x</span></code> are required, but instead of passing spatial weights, a dataframe or numpy array with point coordinates is required as the <code class="docutils literal notranslate"><span class="pre">coords</span></code> argument. The coordinate values are used to build the scaled distance weights. The parameters for those weights are passed as <code class="docutils literal notranslate"><span class="pre">params</span></code>, which is a list of tuples consisting of three elements: the number of nearest
neighbors (<code class="docutils literal notranslate"><span class="pre">k</span></code>), the bandwidth (<code class="docutils literal notranslate"><span class="pre">distance_upper_bound</span></code>), and the transformation. In the most typical application, the same parameters will be used for all the lagged variables so that only a single tuple needs to be specified in the <code class="docutils literal notranslate"><span class="pre">params</span></code> list. However, there is the flexibility to apply a separate set of parameters (and thus a different transformation) to each variable. The sequence of tuples in the list must match the sequence of variable names.</p>
<p>The number of nearest neighbors is used to build the underlying KDTree, and also serves to derive the bandwidth. With the second item as <code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, the bandwidth is adaptive and determined by the distance to the farthest k-nearest neighbor for each observation. For a fixed bandwidth, a distance upper bound must be specified. This is not trivial and depends on the scale of the coordinates (e.g., whether the distance will be in meters or kilometers).</p>
<p>When a distance_upper_bound is set that is larger than the largest k-nearest neighbor distance, there is no effect. In order to be effective, the distance_upper_bound must be less than the maximum k-nearest neighbor distance for a given point. In this instance, it has the effect of imposing a fixed bandwidth, and it truncates the number of nearest neighbors to those within the bandwidth. As a result, the number of neighbors will be less than k. When a strict fixed bandwidth needs to be imposed,
k should be set large enough (and <code class="docutils literal notranslate"><span class="pre">distance_upper_bound</span></code> small enough) so that the bandwidth is effective for every observation.</p>
<p>The third argument is the transformation, either <code class="docutils literal notranslate"><span class="pre">&quot;exponential&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;power&quot;</span></code>. In contrast to the other SLX models, <code class="docutils literal notranslate"><span class="pre">slx_lags</span></code> is <em>not</em> an argument, but <code class="docutils literal notranslate"><span class="pre">slx_vars</span></code> remains available to impose selective lag transformations.</p>
<p>Other arguments include a flag for the type of variance computed, with <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">1</span></code> (the default) for an analytical computation, and <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">0</span></code> for the inverse Hessian approximation. There is also a flag for a listing of a summary of convergence conditions, with <code class="docutils literal notranslate"><span class="pre">conv_flag</span> <span class="pre">=</span> <span class="pre">1</span></code> for such a listing (<code class="docutils literal notranslate"><span class="pre">conv_flag=0</span></code> is the default). Finally, there is a <code class="docutils literal notranslate"><span class="pre">verbose</span></code> flag which lists the intermediate results for all iterations (<code class="docutils literal notranslate"><span class="pre">verbose</span> <span class="pre">=</span> <span class="pre">False</span></code> is the default to avoid sometimes very
long listings), and an option to include <code class="docutils literal notranslate"><span class="pre">minimize</span></code>-specific options, as <code class="docutils literal notranslate"><span class="pre">options</span></code>, a dictionary with specific solver options (see the <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> documentation at <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html</a>).</p>
<p>A final remark is that the results of nonlinear optimization may vary by hardware, operating system and software versions. As a consequence, slight differences in the parameter estimates may occur.</p>
</section>
<section id="Negative-Exponential-Distance">
<h3>Negative Exponential Distance<a class="headerlink" href="#Negative-Exponential-Distance" title="Link to this heading">¶</a></h3>
<section id="Adaptive-bandwidth">
<h4>Adaptive bandwidth<a class="headerlink" href="#Adaptive-bandwidth" title="Link to this heading">¶</a></h4>
<p>The first two examples use an adaptive bandwidth with, respectively, 6 (<strong>parme1</strong>) and 10 (<strong>parme2</strong>) k-nearest neighbors. The adaptive bandwidth is given by <code class="docutils literal notranslate"><span class="pre">np.inf</span></code> and the transformation as <code class="docutils literal notranslate"><span class="pre">&quot;exponential&quot;</span></code>. The coordinates for the weights computation are contained in the numpy array <strong>crdnts</strong>, and <strong>y</strong> and <strong>x</strong> are as before. In the first example, all explanatory variables are lagged, with <code class="docutils literal notranslate"><span class="pre">slx_vars</span> <span class="pre">=</span> <span class="pre">&quot;All&quot;</span></code>. This is the default, so it does not need to be specified as an argument.
It is included here for clarity.</p>
<p>Analytical standard errors are obtained with <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">1</span></code> and a summary of the convergence properties is given with <code class="docutils literal notranslate"><span class="pre">conv_flag</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parme1 = [(6,np.inf,&quot;exponential&quot;)]
parme2 = [(10,np.inf,&quot;exponential&quot;)]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe1 = NSLX(y=y,x=x,coords=crdnts,params=parme1,slx_vars=&quot;All&quot;,
              var_flag=1,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe1.summary)
</pre></div>
</div>
</div>
<p>Even though the optimization process yields estimates, they are clearly suspect, given the associated (analytical) standard errors. The problems seem to be associated with <strong>We_Blk14P</strong> and <strong>We_Hisp14P</strong>, whereas the estimate for <strong>We_EP_NOHSDP</strong> seems more reasonable. The remainder of this example will proceed with just the latter.</p>
<p>Parenthetically, the convergence summary indicates that 95 iterations were used, but gives a success rate of <strong>False</strong>. In this example, this is likely due to some rounding issues and can be ignored. Note that the message states “not necessarily achieved”. A good indication of the extent to which the optimization worked is to compare the sum of squared residuals to that achieved by the other models. At a value of 25,873.8, this is somewhat worse than for the other models, but in the same general
ballpark.</p>
<p>The next model is for the restricted specification.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe2 = NSLX(y=y,x=x,coords=crdnts,params=parme1,slx_vars=[False,False,True],
              var_flag=1,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe2.summary)
</pre></div>
</div>
</div>
<p>The estimated coefficients are identical to those in the full model, and so is the model fit. The only slight difference is in the analytical standard errors for the coefficient of <strong>We_EP_NOHSDP</strong> (0.18474 vs. 0.18572). Also, the number of iterations to convergence is quite a bit smaller than in the previous example (32 vs. 95).</p>
<p>To illustrate the effect of the variance computation, the model is rerun with <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">0</span></code> for a numerical approximation using the inverse Hessian.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe3 = NSLX(y=y,x=x,coords=crdnts,params=parme1,slx_vars=[False,False,True],
              var_flag=0,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe3.summary)
</pre></div>
</div>
</div>
<p>The estimates are again identical, but the associated standard errors are quite different. The analytical derivation for the regression coefficients can be used as a standard for comparison, since it should be <span class="math notranslate nohighlight">\(\sigma^2 (X'X)^{-1}\)</span>. Clearly, this is not the case for the numerical approximation.</p>
<p>The effect of the bandwidth is explored by setting <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">10</span></code>, as in <strong>parme2</strong>. Only the restricted model is considered, with analytical standard errors.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe4 = NSLX(y=y,x=x,coords=crdnts,params=parme2,slx_vars=[False,False,True],
              var_flag=1,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe4.summary)
</pre></div>
</div>
</div>
<p>The regression coefficients are essentially the same as for the model with <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">6</span></code>, but the lag coefficient is larger. Intuitively, this makes sense if the true range of interaction is less than suggested by the bandwidth of <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">10</span></code>. As a consequence, the distance decay should be steeper, implied by the larger coefficient. Otherwise, the fit is marginally better, with a sum of squared residuals of 25,594.8 (compared to 25,873.8).</p>
</section>
<section id="Fixed-bandwidth">
<h4>Fixed bandwidth<a class="headerlink" href="#Fixed-bandwidth" title="Link to this heading">¶</a></h4>
<p>Two upper distance bounds are specified to assess the role of a fixed bandwidth, i.e., 20.0 and 6.0, with <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">6</span></code>. This is specified in the parameter lists <strong>parme3</strong> and <strong>parme4</strong>. Only the restricted model is considered.</p>
<p>To provide some context, for the Chicago SDOH data set, a distance band that ensures that each observation has at least one neighbor (the max-min nearest neighbor distance) is 8.99. For a bandwidth distance of 20, the number of neighbors ranges from 11 to 268, with a median of 153! For a bandwidth distance of 6, there are four observations that become isolates. The number of neighbors ranges from 0 to 40, with 17 as the median.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parme3 = [(6,20.0,&quot;exponential&quot;)]
parme4 = [(6,6.0,&quot;exponential&quot;)]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe5 = NSLX(y=y,x=x,coords=crdnts,params=parme3,slx_vars=[False,False,True],
              var_flag=1,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe5.summary)
</pre></div>
</div>
</div>
<p>The result is identical to the case with an adaptive bandwidth. Even though the listing mentions an upper bound distance of 20, this is ineffective and the k-nearest neighbor criterion dominates.</p>
<p>With an upper bound distance of 6 (<strong>parme4</strong>), the results for the coefficient estimates and model fit are slightly different (the latter is slightly worse, with a sum of squared residuals of 26,000.7).</p>
<p>In general, unless there are good theoretical reasons, an adaptive bandwidth is preferred, since it ensures that there is an equal number of neighbors to each observation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxe6 = NSLX(y=y,x=x,coords=crdnts,params=parme4,slx_vars=[False,False,True],
              var_flag=1,conv_flag=1,
              name_ds=ds_name,verbose=False)
print(nslxe6.summary)
</pre></div>
</div>
</div>
</section>
</section>
<section id="Inverse-Distance-Power">
<h3>Inverse Distance Power<a class="headerlink" href="#Inverse-Distance-Power" title="Link to this heading">¶</a></h3>
<section id="id3">
<h4>Adaptive bandwidth<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h4>
<p>In contrast to the exponential, case, where the effect of bandwidth was explored, here only one case is considered, for an adaptive bandwidth with 6 k-nearest neighbors (<strong>parmp1</strong>). The adaptive bandwidth is given by <code class="docutils literal notranslate"><span class="pre">np.inf</span></code> and the transformation as <code class="docutils literal notranslate"><span class="pre">&quot;power&quot;</span></code>. The coordinates for the weights computation are contained in the numpy array <strong>crdnts</strong>, and <strong>y</strong> and <strong>x</strong> are as before. In the first example, all explanatory variables are lagged, with <code class="docutils literal notranslate"><span class="pre">slx_vars</span> <span class="pre">=</span> <span class="pre">&quot;All&quot;</span></code>. This is the default,
so it does not need to be specified as an argument. As before, it is included here for clarity.</p>
<p>Analytical standard errors are obtained with <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">1</span></code> and a summary of the convergence properties is given with <code class="docutils literal notranslate"><span class="pre">conv_flag</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parmp1 = [(10,np.inf,&quot;power&quot;)]
nslxp1 = NSLX(y=y,x=x,coords=crdnts,params=parmp1,slx_vars=&quot;All&quot;,
              var_flag=1,conv_flag=1,verbose=False,
              name_ds=ds_name)
print(nslxp1.summary)
</pre></div>
</div>
</div>
<p>What happened? The routine produces coefficient estimates, but no standard error or p-values. Closer examination of the results reveals that the <strong>Sum squared residual</strong> has a value of <strong>nan</strong>. The sum of squared residuals is the objective function that is minimized by the nonlinear optimization routine. The result of <strong>nan</strong> indicates a lack of convergence. Also, only two iterations were performed.</p>
<p>This is not a surprise given the very large values for the lag (and other) coefficients. The regression coefficients in particular should be similar to those obtained in OLS and the linear models, which is clearly not the case.</p>
<p>In an attempt to remedy this, the same approach is used as before. The estimation is carried out with the lags for <strong>Blk14P</strong> and <strong>Hisp14P</strong> excluded, using <code class="docutils literal notranslate"><span class="pre">slx_vars</span> <span class="pre">=</span> <span class="pre">[False,False,True]</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxp2 = NSLX(y=y,x=x,coords=crdnts,params=parmp1,slx_vars=[False,False,True],
              var_flag=1,conv_flag=1, verbose=False,
              name_ds=ds_name)
print(nslxp2.summary)
</pre></div>
</div>
</div>
<p>Now, the model seems to converge and yields a parameter value for <strong>Wp_EP_NOHSDP</strong> of 6.30, but no standard errors. The standard errors for the regression coefficients are not affected, but the value for <span class="math notranslate nohighlight">\(\alpha\)</span> causes the matrix product <span class="math notranslate nohighlight">\((\hat{X}'\hat{X})\)</span> to be singular.</p>
<p>The numerical approximation for the inverse Hessian does yield approximate standard errors, but these should be viewed with caution. This is accomplished by setting <code class="docutils literal notranslate"><span class="pre">var_flag</span> <span class="pre">=</span> <span class="pre">0</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nslxp3 = NSLX(y=y,x=x,coords=crdnts,params=parmp1,slx_vars=[False,False,True],
              name_ds=ds_name,
              var_flag=0,conv_flag=1)
print(nslxp3.summary)
</pre></div>
</div>
</div>
<p>The approximation suggests the coefficient is significant. Of all the SLX models, the power function achieves the worst fit (but only marginally so), with a sum of squared residuals of 25,742.3 (compared to 25,594.8 for a similar exponential model).</p>
<p>Clearly, in the current example, there is little gain in going with the nonlinear specification over the linear one. Of all the models, the best fit is achieved by the linear SLX specification based on queen contiguity weights, with a sum of squared residuals of 24,117. However, given the sensitivity of the results to the choice of weights, bandwidth and functional specification, further experimentation would be warranted.</p>
</section>
</section>
<section id="Practice">
<h3>Practice<a class="headerlink" href="#Practice" title="Link to this heading">¶</a></h3>
<p>The SLX model provides the opportunity to compare a wide range of specifications, using different weights and assessing the possible contribution of nonlinear specifications. Try this out for your own baseline model. However, if the diagnostics for spatial dependence in the OLS estimation do not show a significant value for LM-WX statistic, you may need to try a different base specification to obtain meaningful results. Pay particular attention to the interpretation of the coefficients of the
lag terms in relation to Tobler’s law and the sensitivity of the estimates to the choice of a bandwidth.</p>
</section>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../_sources/notebooks/12_estimating_slx.ipynb.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2018-, pysal developers.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 9.1.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>