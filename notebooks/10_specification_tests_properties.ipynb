{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8975c4",
   "metadata": {},
   "source": [
    "# Specification Tests - Properties\n",
    "\n",
    "### Luc Anselin\n",
    "\n",
    "### (revised 09/11/2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd0985",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "In this notebook, a closer look is taken at the properties of the various specification tests for spatial effects. This is carried out by means of a series of simulation experiments on data generated under the null hypothesis of no spatial effects as well as under various alternatives. This provides insight into the distribution of the test statistics under the null and their relative power against various alternatives.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Familiarity with OLS estimation in *spreg* is assumed, as covered in the *OLS notebook* and the *Specification Tests* notebook. For the graphs, it may be useful to have some familiarity with *matplotlib* and the `plot` functionality of *pandas*, although to just replicate the graphs used here, that is not really needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494b68c",
   "metadata": {},
   "source": [
    "### Modules Needed\n",
    "\n",
    "The main module for spatial regression in PySAL is *spreg*. In addition, *libpysal* is needed for spatial weights manipulation, and *pandas* for data frame manipulation. In these exercises, *geopandas* is not needed. In order to get nicer looking graphs, *matplotlib.pyplot* is imported as well, although this is not critical. In addition, the module *time* is used for timing experiments (optional).\n",
    "\n",
    "As before, only the relevant parts of *libpysal* and *spreg* are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e398e42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import libpysal.weights as weights\n",
    "from spreg import OLS, make_x, make_xb, make_wx, make_wxg, \\\n",
    "    make_error, dgp_ols, dgp_lag, dgp_sperror, dgp_slx\n",
    "np.set_printoptions(legacy=\"1.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac85fb3",
   "metadata": {},
   "source": [
    "### Functions Used\n",
    "\n",
    "- from numpy:\n",
    "  - random.default_rng\n",
    "  - rng.chisquare\n",
    "  - zeros\n",
    "  - array\n",
    "  - reshape\n",
    "  - hstack\n",
    "\n",
    "- from pandas:\n",
    "  - DataFrame\n",
    "  - describe\n",
    "  - plot\n",
    " \n",
    "- from matplotlib.pyplot:\n",
    "  - show\n",
    "  \n",
    "- from libpysal:\n",
    "  - weights.lat2W\n",
    "  - w.transform\n",
    "  - w.n\n",
    "  \n",
    "- from spreg:\n",
    "  - OLS\n",
    "  - make_x\n",
    "  - make_xb\n",
    "  - make_wx\n",
    "  - make_wxg\n",
    "  - make_error\n",
    "  - dgp_ols\n",
    "  - dgp_lag\n",
    "  - dgp_sperror\n",
    "  - dgp_slx\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da216d",
   "metadata": {},
   "source": [
    "### Files and Variables\n",
    "\n",
    "In this notebook, no actual data are used, since the data sets will be created by means of simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f82891",
   "metadata": {},
   "source": [
    "## Model Parameters and Variables\n",
    "\n",
    "The various model parameters are set here, so that it is easy to replicate the experiments for different sample sizes and coefficient values.\n",
    "\n",
    "- gridx: the number of cells in the horizontal dimension of a regular lattice of dimension gridx x gridy \n",
    "- gridy: the number of cells in the vertical dimension of a regular lattice of dimension gridx x gridy \n",
    "- b1: a list with regression parameters (includes a coefficient for the constant term as the first element) \n",
    "- k: length of b1 less one (no constant term counted)\n",
    "- rndseed: the random seed to ensure reproducibility \n",
    "- reps: the number of replications \n",
    "- rhovals: a list with spatial autoregressive coefficients $\\rho$ for the lag variables Wy \n",
    "- lamvals: a list with spatial coefficients $\\lambda$ for the error lag variables We \n",
    "- gamvals: a list with coefficients for the SLX variables (WX) \n",
    "- gamma: coefficient for WX in the Spatial Durbin Model \n",
    "\n",
    "- w: queen contiguity spatial weights\n",
    "- n: number of observations\n",
    "- p_value: critical value to be used for tests\n",
    "- x1: x values (not including constant)\n",
    "- xb1: $X \\beta$\n",
    "- wx1: $WX$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ef7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid layout and weights\n",
    "gridx = 20\n",
    "gridy = 20\n",
    "w = weights.lat2W(gridx,gridy,rook=False) \n",
    "w.transform = 'r'\n",
    "n = w.n\n",
    "\n",
    "# model coefficient values\n",
    "b1 = [1, 1, 1, 1]\n",
    "k = len(b1)-1\n",
    "rhovals = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, \n",
    "           0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "lamvals = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, \n",
    "           0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "gamvals = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, \n",
    "           0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "gamma = 0.5\n",
    "\n",
    "# simulation parameters\n",
    "rndseed = 123456789\n",
    "reps = 1000\n",
    "p_value = 0.05\n",
    "\n",
    "# Create X\n",
    "rng=np.random.default_rng(seed=rndseed) # set seed for X\n",
    "xx = make_x(rng,n*k,mu=[0],varu=[6],method=\"uniform\")\n",
    "x1 = np.reshape(xx,(n,k))\n",
    "xb1 = make_xb(x1,b1) # no constant in x1, but a coefficient for the constant in b1\n",
    "wx1 = make_wx(x1,w) # default first order no constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8cd31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of Simulation Design Parameters\")\n",
    "print(\"grid size: \",gridx,\" x \",gridy)\n",
    "print(\"n: \",n,\" k: \",k)\n",
    "print(\"betas: \",b1)\n",
    "print(\"random seed: \",rndseed)\n",
    "print(\"replications: \",reps)\n",
    "print(\"p-value: \",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a81dd",
   "metadata": {},
   "source": [
    "## Distribution Under the Null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90ce6c",
   "metadata": {},
   "source": [
    "The distribution under the null is obtained by simulating **reps** data sets under the null of standard normal errors. The reference distributions for Chi-squared are obtained by means of `rng.chisquare` with the appropriate degrees of freedom. For the LMWX and LMSDM tests, these depend on the number of variables in the X matrix ($k$). \n",
    "\n",
    "The values for the test statistics are taken from the OLS regression object with the arguments `spat_diag=True` and `moran=True`.\n",
    "\n",
    "All the results are collected into a *pandas* dataframe that is then used to compute the descriptive statistics by means of `describe` and to create the various plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# all distributions under the null\n",
    "alltests = [\"N01\",\"Chi2-1\",\"Chi2-2\",\"Chi2-k\",\"Chi2-kr\",\n",
    "            \"Moran\",\"LM-Lag\",\"LM-Error\",\"LMWX\",\n",
    "            \"LMSARER\",\"LMSDM\"]\n",
    "# initialize\n",
    "best = np.zeros((reps,len(alltests)))\n",
    "rng=np.random.default_rng(seed=rndseed)\n",
    "# reference distributions as random number draws\n",
    "# standard normal\n",
    "nn = make_error(rng,reps)\n",
    "best[:,0] = nn[:,0]\n",
    "# chi-squared\n",
    "for j in range(2):\n",
    "    df = j+1\n",
    "    best[:,df] = rng.chisquare(df,reps)\n",
    "for dff in [k,k+1]:  # d.f. for LMWX and LMSDM depends on k\n",
    "    df = df + 1\n",
    "    best[:,df] = rng.chisquare(dff,reps)\n",
    "    \n",
    "# replications\n",
    "for i in range(reps):\n",
    "    u = make_error(rng,n)\n",
    "    \n",
    "    y = dgp_ols(u,xb1)\n",
    "    reg = OLS(y,x1,w=w,spat_diag=True,moran=True)\n",
    "    testres = [reg.moran_res[1],reg.lm_lag[0],reg.lm_error[0],reg.lm_wx[0],\n",
    "                reg.lm_sarma[0],reg.lm_spdurbin[0]]\n",
    "    for jj in range(len(testres)):\n",
    "        best[i,jj+5] = testres[jj]\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)\n",
    "\n",
    "results = pd.DataFrame(best,columns=alltests)\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d56cf2",
   "metadata": {},
   "source": [
    "The most relevant characteristics are the mean and the standard deviation. For the draws from the theoretical distributions, the means are roughly what would be expected, i.e., around 0 for the standard normal, and around the degrees of freedom for the Chi-squared distributions. The standard deviation for the standard normal should be around 1, whereas for the Chi-squared distributions it should be roughly the square root of twice the degrees of freedom. For example, for 1 degree of freedom, it should be around 1.41 (here, 1.26), for two degrees of freedom, around 2 (here, 2.01), etc. \n",
    "\n",
    "The mean for the standardized z-value for Moran's I is -0.015 with a standard deviation of 0.986, close to the moments of a standard normal distribution. The mean of the LM statistics is roughly what would be expected.\n",
    "\n",
    "A closer look at the distribution of the test statistics under the null is obtained in a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0ebe0",
   "metadata": {},
   "source": [
    "### Moran's I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4083b",
   "metadata": {},
   "source": [
    "The `plot` functionality of a *pandas* dataframe is used to create a density plot for Moran's I. It is contrasted with a density plot from simulated standard normal variates. The argument `kind=\"kde\"` is used to obtain a density plot. The columns in the data frame are **N01** and **Moran**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=[\"N01\",\"Moran\"],kind=\"kde\",\n",
    "             title=\"Distribution under Null\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed695f",
   "metadata": {},
   "source": [
    "The result illustrates how Moran's I standardized z-value closely tracks the standard normal distribution under the null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f477764b",
   "metadata": {},
   "source": [
    "### LM-Lag and LM-Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ec31d",
   "metadata": {},
   "source": [
    "For LM-Lag and LM-Error, the reference distribution is a Chi-squared distribution with one degree of freedom. Since the `kde` interpolation results in values less than 0, which is impossible for Chi-squared, the graph is truncated at 0 by means of `xlim=((0,None))`. This still results in a slight bump at zero for one degree of freedom, where in the strict sense there should not be one. For the purposes here, this does not matter.\n",
    "\n",
    "The columns in the data frame are **Chi2-1**, **LM-Lag** and **LM-Error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=[\"Chi2-1\",\"LM-Lag\",\"LM-Error\"],kind=\"kde\",\n",
    "             title=\"Distribution under Null\",xlim=((0,None)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f689bd",
   "metadata": {},
   "source": [
    "In contrast to the results for Moran's I, the graphs closely follow the pattern for the $\\chi^2(1)$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee163a0b",
   "metadata": {},
   "source": [
    "### LM-SARERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b665a13",
   "metadata": {},
   "source": [
    "In the same way, the distribution of LM-SARERROR is compared to a $\\chi^2(2)$ distribution by selecting the proper columns in the data frame, i.e., **Chi2-2** and **LMSARER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65641d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=[\"Chi2-2\",\"LMSARER\"],kind=\"kde\",\n",
    "             title=\"Distribution under Null\",xlim=((0,None)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484123ff",
   "metadata": {},
   "source": [
    "The two plots track closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a6383",
   "metadata": {},
   "source": [
    "### LM-WX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee2d39",
   "metadata": {},
   "source": [
    "The plot for LM-WX is again obtained by selecting the proper columns. The reference distribution is now $\\chi^2(k)$, where $k$ is the number of explanatory variables, not counting the constant. In the example, this is 3. The corresponding columns in the data frame are **Chi2-k** and **LMWX**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=[\"Chi2-k\",\"LMWX\"],kind=\"kde\",\n",
    "             title=\"Distribution under Null\",xlim=((0,None)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb021d",
   "metadata": {},
   "source": [
    "The mode obtained for the test statistic is somewhat smaller than its expected value, but otherwise the two curves track closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192096da",
   "metadata": {},
   "source": [
    "### LM-Spatial Durbin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b65e4f",
   "metadata": {},
   "source": [
    "For the LM-Spatial Durbin test, the theoretical distribution has $k+1$ degrees of freedom, which includes a degree for the spatial autoregressive parameter as well as the explanatory variables. The data frame columns are **Chi2-kr** and **LMSDM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c57720",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=[\"Chi2-kr\",\"LMSDM\"],kind=\"kde\",\n",
    "             title=\"Distribution under Null\",xlim=((0,None)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cac23",
   "metadata": {},
   "source": [
    "The same general pattern is obtained as for LM-WX, i.e., the mode is somewhat lower than the expected theoretical value, but otherwise the two graphs track closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86fce8",
   "metadata": {},
   "source": [
    "## Power Functions - Lag Alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f08fe5-c532-4cb0-baf8-e2ea3e75ca04",
   "metadata": {},
   "source": [
    "Power functions show the rejection percentage of a test statistic for a given p-value at different parameter values for the alternative hypothesis. For the Lag alternative, this is obtained by setting the value for $\\rho$ and generating a vector for $y$ using `dgp_lag`. This dependent variable is then used in a standard OLS regression. For each replication, the p-values for the various spatial diagnostics are extracted from the regression object and compared to the critical value (**p_value**).\n",
    "\n",
    "The comparison is turned into a 0-1 variable for each replication. Finally, the `mean` over all replications is the rejection frequency for each test for the given value of $\\rho$. The resulting array is turned into a *pandas* data frame to `plot` the corresponding power functions.\n",
    "\n",
    "Depending on the hardware, this simulation can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de366884",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = [\"Moran\",\"LM-Lag\",\"LM-Error\",\"LMWX\",\n",
    "         \"LMSARER\",\"LMSDM\",\"RLM-Lag\",\"RLM-Error\",\"RLMWX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad75e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "powvals = np.zeros((len(rhovals),len(pvals)+1))\n",
    "powvals[:,0] = rhovals\n",
    "for r in range(len(rhovals)): \n",
    "    best = np.zeros((reps,len(pvals)))\n",
    "    rng=np.random.default_rng(seed=rndseed)\n",
    "    for i in range(reps):\n",
    "        u = make_error(rng,n)    \n",
    "        y = dgp_lag(u,xb1,w,rho=rhovals[r])\n",
    "        reg = OLS(y,x1,w,spat_diag=True,moran=True)\n",
    "        testp = [reg.moran_res[2],reg.lm_lag[1],reg.lm_error[1],\n",
    "                     reg.lm_wx[1],reg.lm_sarma[1],\n",
    "                     reg.lm_spdurbin[1],reg.rlm_lag[1],\n",
    "                     reg.rlm_error[1],reg.rlm_wx[1]]\n",
    "        best[i,:] = testp\n",
    "    \n",
    "    bestp = (best < p_value) * 1    # significant    \n",
    "    mm = bestp.mean(axis=0)\n",
    "    powvals[r,1:]= mm\n",
    "    \n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)\n",
    "\n",
    "powresult = pd.DataFrame(powvals,columns=[\"rho\"]+pvals)\n",
    "\n",
    "print(\"Test Power for different Rho\")\n",
    "print(powresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d467d",
   "metadata": {},
   "source": [
    "The results data frame shows how the rejection frequency for the various spatial diagnostics changes with the value of the spatial autoregressive parameter $\\rho$.\n",
    "\n",
    "The relative shape of the associated power curves can be compared by means of the `plot` functionality of the *pandas* data frame. For the current purposes, only a rudimentary graph is shown. Fancier versions can be obtained by means of the full functionality of *matplotlib*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620eb16e",
   "metadata": {},
   "source": [
    "### Single alternative tests for Lag and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202611d",
   "metadata": {},
   "source": [
    "The first comparison is between the traditional LM-Lag and LM-Error tests, their robust forms and Moran's I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Lag\",\"RLM-Lag\",\"Moran\",\"LM-Error\",\"RLM-Error\"]\n",
    "powresult.plot(x=\"rho\",y=testnames,\n",
    "               title=\" Lag Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9a38f",
   "metadata": {},
   "source": [
    "The power functions for LM-Lag and its robust form are the two left-most curves. They track each other very closely and achieve a 100% rejection rate for values of $\\rho$ as low as 0.2. Next most powerful are LM-Error and Moran's I, which achieve almost identical power with 100% rejection for $\\rho = 0.3$. Finally, while the robust form of LM-Error provides an effective correction for small values of $\\rho$, it too achieves 100% rejection rate, but for $\\rho = 0.4$. This illustrates the difficulty of identifying the proper alternative when the spatial autoregressive parameter is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1f306",
   "metadata": {},
   "source": [
    "### Lag tests and test against WX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a102155f",
   "metadata": {},
   "source": [
    "A second comparison is between the LM-Lag test and its robust form and the LM test on WX and its robust form (robust to the presence of a spatial lag term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Lag\",\"RLM-Lag\",\"LMWX\",\"RLMWX\"]\n",
    "powresult.plot(x=\"rho\",y=testnames,\n",
    "               title=\" Lag Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f44aed",
   "metadata": {},
   "source": [
    "The power of the LM-WX test tracks that for LM-Lag and Robust LM-Lag very closely, with only slightly less power for the smallest values of $\\rho$. However, just as the for Lag tests, it reaches 100% rejection for $\\rho = 0.2$. In contrast, the robust form of the LM-WX test has much less power and only reaches the 100% rejection rate for $\\rho = 0.45$. This illustrates the effectiveness of the correction for small values of $\\rho$, i.e., for *local* alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac55f9c",
   "metadata": {},
   "source": [
    "### Lag tests and higher order tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448acfd",
   "metadata": {},
   "source": [
    "A final comparison is between the Lag tests and the higher order diagnostics, i.e., LM-SAR-Error and LM-SDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Lag\",\"RLM-Lag\",\"LMSARER\",\"LMSDM\"]\n",
    "powresult.plot(x=\"rho\",y=testnames,\n",
    "               title=\" Lag Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2b862",
   "metadata": {},
   "source": [
    "The results clearly illustrate the unfortunate property of the higher order tests to have strong power against the single parameter Lag alternative. Both LM-SARER and LM-SDM reach 100% rejection for $\\rho = 0.2$ and they have only slightly less power than the Lag tests for smaller values of $\\rho$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3333f",
   "metadata": {},
   "source": [
    "## Power Functions - Error Alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa1806",
   "metadata": {},
   "source": [
    "The same approach can be taken to assess the relative power of the spatial diagnostics against an error alternative. The code is essentially the same as before, except that **lamvals** is used for the spatial parameter and `dgp_sperror` is used for the data generating process.\n",
    "\n",
    "A more pythonic solution would be to put all these operations in a function and pass the dgp as a function object to that function, but the current structure of the `dgp` module makes that difficult to generalize. \n",
    "\n",
    "The same spatial diagnostics as before are considered. The simulation can take quite a bit longer than for the Lag case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = [\"Moran\",\"LM-Lag\",\"LM-Error\",\"LMWX\",\"LMSARER\",\"LMSDM\",\n",
    "         \"RLM-Lag\",\"RLM-Error\",\"RLMWX\"]\n",
    "t0 = time.time()\n",
    "powvals = np.zeros((len(lamvals),len(pvals)+1))\n",
    "powvals[:,0] = lamvals\n",
    "for r in range(len(lamvals)): \n",
    "    best = np.zeros((reps,len(pvals)))\n",
    "    rng=np.random.default_rng(seed=rndseed)\n",
    "    for i in range(reps):\n",
    "        u = make_error(rng,n)    \n",
    "        y = dgp_sperror(u,xb1,w,lam=lamvals[r])\n",
    "        reg = OLS(y,x1,w,spat_diag=True,moran=True)\n",
    "        testp = [reg.moran_res[2],reg.lm_lag[1],reg.lm_error[1],\n",
    "                     reg.lm_wx[1],reg.lm_sarma[1],\n",
    "                     reg.lm_spdurbin[1],reg.rlm_lag[1],\n",
    "                     reg.rlm_error[1],reg.rlm_wx[1]]\n",
    "        best[i,:] = testp\n",
    "    bestp = (best < p_value) * 1    # significant\n",
    "    mm = bestp.mean(axis=0)\n",
    "    powvals[r,1:]= mm\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)\n",
    "\n",
    "powresult = pd.DataFrame(powvals,columns=[\"lam\"]+pvals)\n",
    "\n",
    "print(\"Test Power for different Lambda\")\n",
    "print(powresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf841a",
   "metadata": {},
   "source": [
    "### Single alternative tests for Lag and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdc519",
   "metadata": {},
   "source": [
    "As in the case of the Lag DGP, the first comparison is between the LM tests, their robust versions and Moran's I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Lag\",\"RLM-Lag\",\"Moran\",\n",
    "             \"LM-Error\",\"RLM-Error\"]\n",
    "powresult.plot(x=\"lam\",y=testnames,\n",
    "               title=\" Error Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1159f",
   "metadata": {},
   "source": [
    "The left-most power curves are for Moran's I, LM-Error and Robust LM-Error, which a slight edge for Moran's I for the smaller values of $\\lambda$. Unlike the patterns observed for the Lag alternative, the 100% rejection rate is not reached until $\\lambda = 0.45$ for Moran's I and LM-Error, and $\\lambda = 0.5$ for Robust LM-Error, illustrating an overall lower power of these tests against the error alternative relative to the lag alternative. Also, LM-Lag has much less power against this alternative than LM-Error did against the Lag alternative. Its curve is well to the right of that for the specific error tests and only reaches the 100% rejection rate for $\\lambda = 0.85$. The Robust LM-Lag test has negligible power against the error alternative. Even for $\\lambda = 0.9$, its rejection rate is only 34%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62044597",
   "metadata": {},
   "source": [
    "### Error tests and test against WX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9bcc2",
   "metadata": {},
   "source": [
    "A second comparison is between the two LM tests against error and LM-WX and its robust form (robust against lag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be151f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Error\",\"RLM-Error\",\"LMWX\",\n",
    "             \"RLMWX\"]\n",
    "powresult.plot(x=\"lam\",y=testnames,\n",
    "               title=\" Error Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f30cc",
   "metadata": {},
   "source": [
    "As is to be expected, the LM-Error and Robust LM-Error have the highest power, but surprisingly, the Robust LM-WX has much higher power than LM-WX itself. Its power curve is consistently above that of LM-WX which contradicts the theoretical requirement that the robust form of a test should be smaller than its original value.\n",
    "\n",
    "The LM-WX test only reaches a 60.6% rejection rate for $\\lambda = 0.9$, whereas Robust LM-WX has a 100% rejection rate for $\\lambda = 0.5$, essentially the same as Robust LM-Error, although it remains below the two LM curves for all smaller values of $\\lambda$.\n",
    "\n",
    "This phenomenon illustrates the *two out of three* problem associated with the robust LM-tests, namely that they are constructed to take into account only one of potentially two types of misspecification. In this case, the correction of LM-WX is for the presence of a spatial Lag term, but the actual DGP is a spatial error model, which is no longer a *local* alternative, hence the strange behavior of the robust test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a75771",
   "metadata": {},
   "source": [
    "### Error tests and higher order tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e07985",
   "metadata": {},
   "source": [
    "The final comparison is between LM-Error and its Robust form and the LM-SARER and LM-SDM tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ff5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LM-Error\",\"RLM-Error\",\"LMSARER\",\n",
    "             \"LMSDM\"]\n",
    "powresult.plot(x=\"lam\",y=testnames,\n",
    "               title=\" Error Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910c02f",
   "metadata": {},
   "source": [
    "As was the case for the Lag DGP, the LM-SARER test has strong power against the one-directional error alternative. It reaches 100\\% rejection rate for $\\lambda = 0.5$, the same as the robust LM-Error, although for the smaller values of $\\lambda$ its power curve is always slightly below those of the one-directional LM tests. \n",
    "\n",
    "More disturbingly are the results for a two-directional test against the spatial Durbin DGP (i.e., both $\\rho$ and $\\gamma$ non-zero), which obtains almost the same power as the other tests against the error DGP. In other words, even in the total absence of a SDM model, the LM-SDM test will point to that alternative when the true DGP is an error model. At some level, this may be expected, since SDM is equivalent to an error specification under the spatial common factor coefficient constraints. However, in practice, this result may be confusing. One would expect that after estimating a SDM, the common factor test would point to an error specification, but this is not the most efficient approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac105c5",
   "metadata": {},
   "source": [
    "## Power Functions - SLX Alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcfec9",
   "metadata": {},
   "source": [
    "A final analysis of the power of the various spatial diagnostics is when the alternative is an SLX model. The same approach is taken as for the other two cases, but this time the loop is over the values of $\\gamma$, the coefficients of the WX variables. For the sake of simplicity, these are taken to be the same for each spatially lagged explanatory variable.\n",
    "\n",
    "The code is again essentially the same as before, except that now the argument **wxg1** must be calculated for each value of $\\gamma$ and then passed to the `dgp_slx`function for the data generating process. The results are again collected in a data frame for visualization.\n",
    "\n",
    "This simulation takes slightly less time than the previous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = [\"Moran\",\"LM-Lag\",\"LM-Error\",\"LMWX\",\"LMSARER\",\n",
    "         \"LMSDM\",\"RLM-Lag\",\"RLM-Error\",\"RLMWX\"]\n",
    "t0 = time.time()\n",
    "powvals = np.zeros((len(gamvals),len(pvals)+1))\n",
    "powvals[:,0] = gamvals\n",
    "for r in range(len(gamvals)):\n",
    "    g = gamvals[r]\n",
    "    gg = [g for i in b1[0:-1]]    # create list of gamma values of the correct length\n",
    "    wxg1 = make_wxg(wx1,gg)\n",
    "    best = np.zeros((reps,len(pvals)))\n",
    "    rng=np.random.default_rng(seed=rndseed)\n",
    "    for i in range(reps):\n",
    "        u = make_error(rng,n)    \n",
    "        y = dgp_slx(u,xb1,wxg1)\n",
    "        reg = OLS(y,x1,w,spat_diag=True,moran=True)\n",
    "        testp = [reg.moran_res[2],reg.lm_lag[1],reg.lm_error[1],reg.lm_wx[1],reg.lm_sarma[1],\n",
    "                     reg.lm_spdurbin[1],reg.rlm_lag[1],reg.rlm_error[1],reg.rlm_wx[1]]\n",
    "        best[i,:] = testp\n",
    "    bestp = (best < p_value) * 1    # significant\n",
    "    mm = bestp.mean(axis=0)\n",
    "    powvals[r,1:]= mm\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)\n",
    "\n",
    "powresult = pd.DataFrame(powvals,columns=[\"gam\"]+pvals)\n",
    "\n",
    "print(\"Test Power for different Gamma\")\n",
    "print(powresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6001d",
   "metadata": {},
   "source": [
    "### SLX tests and Moran's I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d923c6",
   "metadata": {},
   "source": [
    "As a first comparison, the power curves of LM-WX and its Robust version are plotted together with the power curve of Moran's I for this alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LMWX\",\"RLMWX\",\"Moran\"]\n",
    "powresult.plot(x=\"gam\",y=testnames,\n",
    "               title=\" SLX Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174464f",
   "metadata": {},
   "source": [
    "Overall, the LM-WX test has good power, achieving a 100% rejection rate for $\\gamma = 0.2$. Not unsurprisingly, Moran's I has decent power against this alternative as well, illustrating its usefulness as a misspecification test. Its only starts to gain power around $\\gamma = 0.2$, but reaches 100% rejection rate for $\\gamma = 0.45$.\n",
    "\n",
    "On the other hand, the shape of the power curve for Robust LM-WS is bizarre. The test has essentially no power at all after correcting for the (inappropriate) presence of a spatial autoregressive term. This again illustrates how the robustness correction is not appropriate when the ignored alternative is not local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e939b",
   "metadata": {},
   "source": [
    "### SLX tests and Error tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62196aa",
   "metadata": {},
   "source": [
    "A second comparison rates the power curve for LM-WX against that for the LM-Error test and its robust form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LMWX\",\"RLMWX\",\"LM-Error\",\"RLM-Error\"]\n",
    "powresult.plot(x=\"gam\",y=testnames,\n",
    "               title=\" SLX Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4022f0",
   "metadata": {},
   "source": [
    "Whereas the LM-Error test has power against the SLX alternative, similar to that of Moran's I, its robust version does not. Since it corrects for an inappropriate DGP, its behavior is non-standard and it has essentially no power against this alternative. LM-Error has slightly less power than Moran's I (in the previous graph), but also reaches the 100% rejection rate for $\\gamma = 0.45$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91c7bc",
   "metadata": {},
   "source": [
    "### SLX tests and Lag tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd7427",
   "metadata": {},
   "source": [
    "Another interesting comparison is between LM-WX and the power curves for LM-Lag and its robust form. In contrast to the LM-Error DGP, which has no commonality with the SLX DGP, the latter can be considered as a truncated form of the Lag DGP. Hence one would expect the Lag tests to have some power against the SLX alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LMWX\",\"RLMWX\",\"LM-Lag\",\"RLM-Lag\"]\n",
    "powresult.plot(x=\"gam\",y=testnames,\n",
    "               title=\" SLX Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627dad7",
   "metadata": {},
   "source": [
    "The Lag tests indeed show strong power against the SLX alternative. In fact, for small values of $\\gamma$, their power slightly exceeds that of LM-WX. In this case as well, the robust form of LM-Lag corrects for the wrong alternative. As a result, it tends to have slightly higher power than LM-Lag itself, which is not the proper behavior. All three tests achieve 100% rejection rate for $\\gamma = 0.2$. The graph for RLMWX is the same as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbde58",
   "metadata": {},
   "source": [
    "### SLX tests and higher error tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feee3f2",
   "metadata": {},
   "source": [
    "A final comparison is between the LM-WX test and the two higher order tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testnames = [\"LMWX\",\"RLMWX\",\"LMSARER\",\"LMSDM\"]\n",
    "powresult.plot(x=\"gam\",y=testnames,\n",
    "               title=\" SLX Alternative - Power Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9845291",
   "metadata": {},
   "source": [
    "In this case as well, the power curves of the higher order tests closely track that for LM-WX, achieving 100% rejection rate for $\\gamma = 0.2$. For the smaller values of $\\gamma$, the power of LM-SARER is slightly higher and that of LM-SDM slightly lower than that of LM-WX.\n",
    "\n",
    "This again highlights the caution that is needed when interpreting the results of the higher order tests. Both also have excellent power against one-directional alternatives, which can easily provide misleading guidance in a specification search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aadbff",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "The range of comparisons can easily be expanded using different spatial layouts and associated sample sizes as well as different DGP, such as a moving average error process, or various higher order DGP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
